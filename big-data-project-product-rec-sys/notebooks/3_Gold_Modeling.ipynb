{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d519f404-ae2c-4dff-8479-d77a1893a0e9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define your project structure names\n",
    "catalog_name = \"big_data_project\"\n",
    "silver_schema_name = \"silver\"\n",
    "gold_schema_name = \"gold\"\n",
    "\n",
    "# Define the full table names we will use\n",
    "silver_table = f\"{catalog_name}.{silver_schema_name}.products_cleaned\"\n",
    "gold_table = f\"{catalog_name}.{gold_schema_name}.products_with_features\"\n",
    "\n",
    "# Load the cleaned data from the silver table\n",
    "silver_df = spark.table(silver_table)\n",
    "\n",
    "print(f\"Successfully loaded Silver table: {silver_table}\")\n",
    "display(silver_df.limit(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2d2fc1eb-51ba-4d21-a81f-2b150579b083",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# 1. Tokenizer: Split \"searchable_text\" into \"words\"\n",
    "tokenizer = Tokenizer(inputCol=\"searchable_text\", outputCol=\"words\")\n",
    "\n",
    "# 2. StopWordsRemover: Take \"words\" and create \"filtered_words\"\n",
    "stopwords_remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered_words\")\n",
    "\n",
    "# 3. HashingTF: Converts the words into a sparse vector of term frequencies (counts).\n",
    "# We set a large number of features, but it only stores the ones it finds.\n",
    "hashingTF = HashingTF(inputCol=\"filtered_words\", outputCol=\"rawFeatures\", numFeatures=20000)\n",
    "\n",
    "# 4. IDF: This is our ML model. It weighs the counts,\n",
    "# making rare (and more important) words have a higher score.\n",
    "# This model is very small.\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\") # 'features' is our final vector\n",
    "\n",
    "# 5. Assemble all steps into the new pipeline\n",
    "pipeline = Pipeline(stages=[tokenizer, stopwords_remover, hashingTF, idf])\n",
    "\n",
    "print(\"MLlib pipeline (using TF-IDF) created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e0b867a4-4adc-4f36-834c-39b0ed9e2099",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Fit the pipeline to the silver data to train the model\n",
    "pipeline_model = pipeline.fit(silver_df)\n",
    "\n",
    "# Transform the data to add the new 'features' column\n",
    "vectorized_data_df = pipeline_model.transform(silver_df)\n",
    "\n",
    "# Select only the columns we need for the final gold table\n",
    "# The 'features' column is our new model output!\n",
    "gold_df = vectorized_data_df.select(\n",
    "    \"asin\",\n",
    "    \"title\",\n",
    "    \"productURL\",\n",
    "    \"imgUrl\",\n",
    "    \"price\",\n",
    "    \"stars\",\n",
    "    \"category_name\",\n",
    "    \"features\"  # This is the all-important ML vector\n",
    ")\n",
    "\n",
    "print(\"Model training complete. Data transformed with feature vectors.\")\n",
    "display(gold_df.limit(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ebfbdf31-2c32-41be-86ba-137c7932bdf3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Save the final table with ML features to the gold database\n",
    "gold_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(gold_table)\n",
    "\n",
    "print(f\"Successfully created Gold table: {gold_table}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7b0035d3-7f44-4ba6-b532-6df8984bc924",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "3_Gold_Modeling",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
